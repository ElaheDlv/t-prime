#!/usr/bin/env python3
"""
chunk_dataset_sigmf.py

Chunks SigMF-based IQ captures into MATLAB .mat and YAML files
matching an example waveform length. It flattens nested subfolders
by randomly sampling up to `num_examples` frames per class,
then cutting each into frames of length `frame_len` (taken from an example .mat).
Metadata .yaml files are generated by extracting the `transmitter` info from
each SigMF metadata (`.sigmf-meta`) under `annotations.signal.detail.transmitter`.

Usage:
  python chunk_dataset_sigmf.py \
    --input_dir /path/to/sigmf_dataset_root \
    --example_mat /path/to/example_frame.mat \
    --output_dir /path/to/output_mat_yaml \
    --num_examples 2000
"""
import argparse
from pathlib import Path
import random
import json
import numpy as np
import scipy.io
import shutil
import yaml
import sys

SIGMF_DATA_EXT = '.sigmf-data'
SIGMF_META_EXT = '.sigmf-meta'


def load_waveform_mat(mat_path: Path) -> np.ndarray:
    """Load waveform array from .mat (v7/v7.3) using scipy.io loadmat."""
    try:
        data = scipy.io.loadmat(str(mat_path))
        if 'waveform' in data:
            arr = data['waveform']
        else:
            # fallback: first ndarray in file
            arr = next(v for v in data.values() if isinstance(v, np.ndarray))
        return np.array(arr).flatten()
    except Exception:
        # fallback for v7.3 HDF5
        import h5py
        with h5py.File(str(mat_path), 'r') as f:
            key = next(iter(f.keys()))
            return np.array(f[key]).flatten()


def load_sigmf_data(data_path: Path) -> np.ndarray:
    # raw binary of complex64 interleaved I/Q
    return np.fromfile(str(data_path), dtype=np.complex64)


def load_sigmf_meta(meta_path: Path) -> dict:
    with open(meta_path, 'r') as f:
        meta = json.load(f)
    # locate annotations.signal.detail.transmitter
    for ann in meta.get('annotations', []):
        sig = ann.get('signal', {})
        detail = sig.get('detail', {})
        tx = detail.get('transmitter')
        if tx:
            return tx
    return {}


def chunk_signal(sig: np.ndarray, frame_len: int):
    n_frames = len(sig) // frame_len
    for i in range(n_frames):
        yield i, sig[i*frame_len:(i+1)*frame_len]


def main():
    parser = argparse.ArgumentParser(description="Chunk SigMF IQ dataset into .mat/.yaml frames")
    parser.add_argument('--input_dir',   required=True, help="Root directory of SigMF dataset")
    parser.add_argument('--example_mat', required=True, help="Example .mat to match frame length and dtype")
    parser.add_argument('--output_dir',  required=True, help="Where to write .mat and .yaml frames")
    parser.add_argument('--num_examples', type=int, required=True,
                        help="Total frames to generate per class")
    args = parser.parse_args()

    in_root = Path(args.input_dir).expanduser().resolve()
    example_mat = Path(args.example_mat).expanduser().resolve()
    out_root = Path(args.output_dir).expanduser().resolve()

    if not in_root.is_dir(): sys.exit(f"Input_dir {in_root} not found")
    if not example_mat.exists(): sys.exit(f"Example_mat {example_mat} not found")
    out_root.mkdir(parents=True, exist_ok=True)

    # load example to get frame length and dtype
    frame = load_waveform_mat(example_mat)
    frame_len = frame.shape[0]
    dtype = frame.dtype
    print(f"Using frame length={frame_len}, dtype={dtype}")

    # for each class (subdir under input_dir)
    for cls_dir in sorted(in_root.iterdir()):
        if not cls_dir.is_dir(): continue
        cls_name = cls_dir.name
        print(f"Processing class: {cls_name}")
        # gather all sigmf-data files under nested subfolders
        all_data = list(cls_dir.rglob(f"*{SIGMF_DATA_EXT}"))
        random.shuffle(all_data)

        dest_dir = out_root / cls_name
        dest_dir.mkdir(parents=True, exist_ok=True)

        count = 0
        for data_file in all_data:
            if count >= args.num_examples:
                break
            meta_file = data_file.with_suffix(SIGMF_META_EXT)
            if not meta_file.exists():
                print(f"Warn: missing meta for {data_file.name}")
                continue
            sig = load_sigmf_data(data_file)
            tx_meta = load_sigmf_meta(meta_file)
            for idx, seg in chunk_signal(sig, frame_len):
                if count >= args.num_examples:
                    break
                seg_col = seg.reshape(-1, 1).astype(dtype)
                stem = f"{data_file.stem}_chunk{idx:04d}"
                out_mat = dest_dir / f"{stem}.mat"
                scipy.io.savemat(str(out_mat), {'waveform': seg_col})
                out_yaml = dest_dir / f"{stem}.yaml"
                with open(out_yaml, 'w') as yf:
                    yaml.dump({'transmitter': tx_meta}, yf)
                count += 1
        print(f"  -> generated {count} frames for class {cls_name}")

if __name__ == '__main__':
    main()
